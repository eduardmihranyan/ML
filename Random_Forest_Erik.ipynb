{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Decision Tree Accuracy =  0.77037037037  ( 0.0431922362581 )\n",
      "Random Forest Tree Accuracy =  0.8  ( 0.0554319612855 )\n",
      "Logistic Reg. Accuracy =  0.444444444444  ( 0.0844574388962 )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from logistic_regression import gradient_descent\n",
    "from logistic_regression import log_pred\n",
    "from random_forest import RandomForest\n",
    "from decision_tree import DecisionTree\n",
    "\n",
    "\n",
    "def accuracy_score(Y_true, Y_predict):\n",
    "    cor_count=0\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_predict[i]==Y_true[i]:\n",
    "            cor_count+=1\n",
    "    acc=cor_count/len(Y_true)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def evaluate_performance():\n",
    "    '''\n",
    "    Evaluate the performance of decision trees and logistic regression,\n",
    "    average over 1,000 trials of 10-fold cross validation\n",
    "\n",
    "    Return:\n",
    "      a matrix giving the performance that will contain the following entries:\n",
    "      stats[0,0] = mean accuracy of decision tree\n",
    "      stats[0,1] = std deviation of decision tree accuracy\n",
    "      stats[1,0] = mean accuracy of logistic regression\n",
    "      stats[1,1] = std deviation of logistic regression accuracy\n",
    "\n",
    "    ** Note that your implementation must follow this API**\n",
    "    '''\n",
    "\n",
    "    # Load Data\n",
    "    filename = 'data/SPECTF.dat'\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    X = data[:, 1:]\n",
    "    Y = np.array(data[:, 0])\n",
    "    n, d = X.shape\n",
    "    N_folds = 10\n",
    "\n",
    "    des_tree_acc = []\n",
    "    rand_forest_acc = []\n",
    "    log_acc = []\n",
    "\n",
    "    for trial in range(5):\n",
    "        print(trial)\n",
    "        idx = np.arange(n) #shuffling data\n",
    "        np.random.seed(13)\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        Y = Y[idx]\n",
    "\n",
    "        X_train=X[:int(n*0.9),:]\n",
    "        X_val=X[int(n*0.9):,:]\n",
    "        Y_train=Y[:int(n*0.9)]\n",
    "        Y_val=Y[int(n*0.9):]\n",
    "\n",
    "        # training the decision tree\n",
    "        des_tree = DecisionTree(100) #create a decision tree with max_depth=100\n",
    "        des_tree.fit(X_train, Y_train)\n",
    "        des_tree_pred = des_tree.predict(X_val)\n",
    "        des_tree_accuracy = accuracy_score(Y_val, des_tree_pred)\n",
    "        des_tree_acc.append(des_tree_accuracy)\n",
    "\n",
    "        # training the random forest\n",
    "        rand_forest = RandomForest(10, 100) # create a random forest with number of trees: 10 and max depth: 100\n",
    "        rand_forest.fit(X_train, Y_train)\n",
    "        rand_forest_pred = rand_forest.predict(X_val)[0] #[0] indicates tuple member, because predict returns (Y,conf)\n",
    "        rand_forest_accuracy = accuracy_score(Y_val, rand_forest_pred)\n",
    "        rand_forest_acc.append(rand_forest_accuracy)\n",
    "\n",
    "        #training the logistic regression\n",
    "        weights = gradient_descent(X_train, Y_train, step_size=1e-3, max_steps=500)\n",
    "        log_predicted = log_pred(X_val, weights)\n",
    "        log_accuracy = accuracy_score(Y_val, log_predicted)\n",
    "        log_acc.append(log_accuracy)\n",
    "\n",
    "    # compute the training accuracy of the model\n",
    "    meanDecisionTreeAccuracy = np.mean(des_tree_acc)\n",
    "    stddevDecisionTreeAccuracy = np.std(des_tree_acc)\n",
    "    meanLogisticRegressionAccuracy = np.mean(log_acc)\n",
    "    stddevLogisticRegressionAccuracy = np.std(log_acc)\n",
    "    meanRandomForestAccuracy = np.mean(rand_forest_acc)\n",
    "    stddevRandomForestAccuracy = np.std(rand_forest_acc)\n",
    "\n",
    "    # make certain that the return value matches the API specification\n",
    "    stats = np.zeros((3, 2))\n",
    "    stats[0, 0] = meanDecisionTreeAccuracy\n",
    "    stats[0, 1] = stddevDecisionTreeAccuracy\n",
    "    stats[1, 0] = meanRandomForestAccuracy\n",
    "    stats[1, 1] = stddevRandomForestAccuracy\n",
    "    stats[2, 0] = meanLogisticRegressionAccuracy\n",
    "    stats[2, 1] = stddevLogisticRegressionAccuracy\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Do not modify from HERE...\n",
    "if __name__ == \"__main__\":\n",
    "    stats = evaluate_performance()\n",
    "    print(\"Decision Tree Accuracy = \", stats[0, 0], \" (\", stats[0, 1], \")\")\n",
    "    print(\"Random Forest Tree Accuracy = \", stats[1, 0], \" (\", stats[1, 1], \")\")\n",
    "    print(\"Logistic Reg. Accuracy = \", stats[2, 0], \" (\", stats[2, 1], \")\")\n",
    "# ...to HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
